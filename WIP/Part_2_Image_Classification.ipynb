{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> AutoAI4EO: NAS with AutoKeras for Earth Observation (Part 2) <h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This is the second blog post in the series about our research on Neural Architecture Search (NAS) for Earth Observation (EO). In Part 1 < link > we introduced NAS and how it can be applied to EO. We talked about a NAS framework: AutoKeras [1], and briefly discussed how it can be customized for EO tasks. In this blog post, we are going to dive more in-depth into how AutoKeras can be used to create methods for EO imagery. More specifically, we are going to tackle the task of classification of EO imagery through the work “Automated Machine Learning for Satellite Data: Integrating Remote Sensing Pre-trained Models into AutoML Systems” by Nelly R. Palacios Salinas, Mitra Baratchi, Jan N. van Rijn and Andreas Vollrath [2].</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Classification </h2>\n",
    "<p> Image classification is the task of assigning labels to an image. For instance, you’d like to know whether your image is showing a desert or a forest. Classification has, among others, applications in tasks like urban planning, hazard detection, and monitoring of the environment [3]. Sometimes in EO the term “image classification” is used to refer to what is called segmentation in computer science. This is the task of assigning labels to individual pixels. For instance, you want to know of each individual pixel whether it is part of a building or not. However, we will only talk about classification in the traditional sense, where you consider the complete image. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 10:01:44.870254: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-20 10:01:45.131365: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-20 10:01:45.185163: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-20 10:01:45.185179: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-20 10:01:45.227799: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-20 10:01:46.072088: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-20 10:01:46.072192: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-20 10:01:46.072199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperBlock(ak.Block):\n",
    "        \n",
    "    def build(self, hp, inputs):\n",
    "        inputs = tf.nest.flatten(inputs)[0]\n",
    "        \n",
    "        if hp.Choice(\"model_type\",[\"resnet\", \"xception\"]) == \"resnet\":\n",
    "            outputs = ak.ResNetBlock().build(hp,inputs)\n",
    "        else:\n",
    "            outputs=ak.XceptionBlock().build(hp,inputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class HyperBlock(ak.Block):\n",
    "    def __init__(self, model_type: Optional[str] = None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        if model_type is not None and model_type != \"resnet\" and model_type != \"wdsr\":\n",
    "            raise Exception(f\"invalid model_type {model_type}\")\n",
    "\n",
    "        self.model_type=model_type\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"model_type\": self.model_type})\n",
    "        return config\n",
    "\n",
    "    def _build_model(self,hp, output_node,model_type: str):\n",
    "        if model_type==\"resnet\":\n",
    "            return ak.ResNetBlock().build(hp,output_node)\n",
    "        elif model_type==\"xception\":\n",
    "            return ak.XceptionBlock().build(hp, output_node)\n",
    "\n",
    "    def build(self, hp, inputs):\n",
    "        inputs=tf.nest.flatten(inputs)[0]\n",
    "\n",
    "        # Let AutoKeras choose a model\n",
    "        if self.model_type is None:\n",
    "            model_type= hp.Choice(\"model_type\", [\"resnet\", \"xception\"])\n",
    "            with hp.conditional_scope(\"model_type\",[model_type]):\n",
    "                outputs = self._build_model(hp,inputs,model_type)\n",
    "        # Select model yourself\n",
    "        else:\n",
    "            outputs = self._build_model(hp,inputs,model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EO_VERSIONS= {\n",
    "    \"resisc45\": \"https://tfhub.dev/google/remote_sensing/resisc45-resnet50/1\",\n",
    "    \"eurosat\": \"https://tfhub.dev/google/remote_sensing/eurosat-resnet50/1\",\n",
    "    \"so2sat\": \"https://tfhub.dev/google/remote_sensing/so2sat-resnet50/1\",\n",
    "    \"ucmerced\": \"https://tfhub.dev/google/remote_sensing/uc_merced-resnet50/1\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([\"eurosat\", \"so2sat\"]) <= set(EO_VERSIONS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "class EOResNetBlock(ak.Block):\n",
    "    #Remote sensing pretrained modules based on: https://github.com/palaciosnrps/automl-rs-project/blob/714bbe36c68fd0f2b989bfee89eac9497d7acf45/autokeras/blocks/basic.py\"\"\"\n",
    "    def __init__(\n",
    "         self, \n",
    "         version: Optional[str] = None,\n",
    "         **kwargs,\n",
    "         ):\n",
    "            super().__init__(**kwargs)\n",
    "\n",
    "            if version is not None and version not in EO_VERSIONS.keys() and set(version) <= set(EO_VERSIONS.keys()):\n",
    "                raise Exception(f\"invalid version {version}\")\n",
    "        \n",
    "            self.version=version\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"version\": self.version})\n",
    "        return config\n",
    "\n",
    "    def build(self, hp, inputs=None):\n",
    "        # Get the input_node from inputs.\n",
    "\n",
    "        input_node = tf.nest.flatten(inputs)[0]\n",
    "\n",
    "        if self.version is None:\n",
    "            version= hp.Choice(\"version\", list(EO_VERSIONS.keys()))\n",
    "        elif isinstance(self.version,list):\n",
    "            version = self.version\n",
    "        else:\n",
    "            version = [self.version]\n",
    "            \n",
    "        module = hub.KerasLayer(EO_VERSIONS[version],tags='train',trainable=False)\n",
    "        min_size = 224\n",
    "        if input_node.shape[3] not in [1, 3]:\n",
    "            if self.pretrained:\n",
    "                raise ValueError(\n",
    "                    \"When pretrained is set to True, expect input to \"\n",
    "                    \"have 1 or 3 channels, bug got \"\n",
    "                    \"{channels}.\".format(channels=input_node.shape[3])\n",
    "                )\n",
    "\n",
    "        if input_node.shape[1] < min_size or input_node.shape[2] < min_size:\n",
    "            input_node = tf.keras.layers.experimental.preprocessing.Resizing(\n",
    "                max(min_size, input_node.shape[1]),\n",
    "                max(min_size, input_node.shape[2]),\n",
    "            )(input_node)\n",
    "        if input_node.shape[3] == 1:\n",
    "            input_node = tf.keras.layers.Concatenate()([input_node] * 3)\n",
    "        if input_node.shape[3] != 3:\n",
    "            input_node = tf.keras.layers.Conv2D(filters=3, kernel_size=1, padding=\"same\")(\n",
    "                input_node\n",
    "            )\t\n",
    "\n",
    "        output_node = module(input_node)\n",
    "        return output_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperBlock(ak.Block):\n",
    "    def __init__(self, model_type: Optional[str] = None, version: Optional[str] = None,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        if model_type is not None and model_type != \"resnet\" and model_type != \"wdsr\" and model_type != \"eo_resnet\":\n",
    "            raise Exception(f\"invalid model_type {model_type}\")\n",
    "\n",
    "        self.model_type=model_type\n",
    "        print(self.model_type)\n",
    "        self.version = version\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"model_type\": self.model_type})\n",
    "        return config\n",
    "\n",
    "    def _build_model(self,hp, output_node,model_type: str):\n",
    "        if model_type==\"resnet\":\n",
    "            print(\"build resnet\")\n",
    "            return ak.ResNetBlock().build(hp,output_node)\n",
    "        elif model_type==\"xception\":\n",
    "            return ak.XceptionBlock().build(hp, output_node)\n",
    "        elif model_type==\"eo_resnet\":\n",
    "            return EOResNetBlock(version=self.version).build(hp,output_node)\n",
    "\n",
    "    def build(self, hp, inputs):\n",
    "        inputs=tf.nest.flatten(inputs)[0]\n",
    "\n",
    "        # Let AutoKeras choose a model\n",
    "        if self.model_type is None:\n",
    "            model_type= hp.Choice(\"model_type\", [\"resnet\", \"xception\", \"eo_resnet\"])\n",
    "            with hp.conditional_scope(\"model_type\",[model_type]):\n",
    "                outputs = self._build_model(hp,inputs,model_type)\n",
    "        # Select model yourself\n",
    "        else:\n",
    "            outputs = self._build_model(hp,inputs,self.model_type)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resisc45': 'https://tfhub.dev/google/remote_sensing/resisc45-resnet50/1',\n",
       " 'eurosat': 'https://tfhub.dev/google/remote_sensing/eurosat-resnet50/1',\n",
       " 'so2sat': 'https://tfhub.dev/google/remote_sensing/so2sat-resnet50/1'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k,v in EO_VERSIONS.items() if k!= \"ucmerced\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 10:01:48.714355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-20 10:01:48.714579: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-20 10:01:48.714641: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-20 10:01:48.714673: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-20 10:01:48.714700: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-20 10:01:48.714728: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-20 10:01:48.714754: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-20 10:01:48.714781: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-20 10:01:48.714807: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-20 10:01:48.714814: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-10-20 10:01:48.716911: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "# load the dataset 317.MiB\n",
    "train_set=tfds.as_numpy(tfds.load(\"uc_merced\", download=False,as_supervised=False, batch_size=-1,split=\"train[:80%]\"))\n",
    "test_set=tfds.as_numpy(tfds.load(\"uc_merced\", download=False,as_supervised=False, batch_size=-1,split=\"train[80%:]\"))\n",
    "\n",
    "weights_versions = {k: v for k,v in EO_VERSIONS.items() if k != \"ucmerced\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eo_resnet\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "eurosat           |?                 |hyper_block_1/eo_res_net_block_1/version\n",
      "0                 |?                 |classification_head_1/dropout\n",
      "adam              |?                 |optimizer\n",
      "0.001             |?                 |learning_rate\n",
      "\n",
      "Epoch 1/1000\n",
      "43/43 [==============================] - 58s 1s/step - loss: 1.6387 - accuracy: 0.5218 - val_loss: 0.9212 - val_accuracy: 0.7401\n",
      "Epoch 2/1000\n",
      "43/43 [==============================] - 58s 1s/step - loss: 0.6647 - accuracy: 0.8198 - val_loss: 0.6784 - val_accuracy: 0.7961\n",
      "Epoch 3/1000\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.4644 - accuracy: 0.8917"
     ]
    }
   ],
   "source": [
    "# tf.enable_eager_execution()\n",
    "input_node = ak.ImageInput()\n",
    "output_node = HyperBlock(model_type=\"eo_resnet\")(input_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "eo_nas_model = ak.AutoModel(input_node, output_node, max_trials=1,overwrite=True)\n",
    "\n",
    "eo_nas_model.fit(x=train_set[\"image\"], y=train_set[\"label\"], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas_eo_env",
   "language": "python",
   "name": "nas_eo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
